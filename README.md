# ğŸ”¥ Burner Power Optimizer with XGBoost and Optuna

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.12%2B-blue.svg)](https://www.python.org/)
[![XGBoost](https://img.shields.io/badge/XGBoost-Model-green)](https://xgboost.readthedocs.io/)
[![Optuna](https://img.shields.io/badge/Optuna-HPO-orange)](https://optuna.org/)

A robust and modular Python tool for training an optimized XGBoost regression model to predict burner power.  
It connects directly to a MySQL database, performs feature engineering, optimizes hyperparameters with Optuna, logs the entire process, and stores performance metrics in a custom SQL table.

---

## ğŸ§  Overview

This project helps optimize burner power prediction in industrial processes by:

- ğŸ—ƒï¸ Extracting data from a MySQL production database  
- ğŸ§¹ Preprocessing and engineering domain-specific features  
- âš™ï¸ Automatically optimizing model hyperparameters using [Optuna](https://optuna.org)  
- â™»ï¸ Training a powerful [XGBoost](https://xgboost.readthedocs.io/) regression model  
- ğŸ“Š Logging and saving model performance metrics (MAE, RMSE, RÂ², etc.)  
- ğŸ“€ Exporting the model and transformer to a `.pkl` file  
- ğŸ§± Saving results into a SQL table for traceability  

---

## ğŸ“‚ Project Structure

```
burner-power-optimizer/
â”œâ”€â”€ burner_model_trainer.py          # Main training script and class definition
â”œâ”€â”€ burner_model.pkl                 # Output: Trained model and transformer (generated after running)
â”œâ”€â”€ requirements.txt                 # List of Python dependencies
â”œâ”€â”€ README.md                        # Project documentation (this file)
â”œâ”€â”€ LICENSE                          # Open-source license (MIT)
â””â”€â”€ logs/
    â””â”€â”€ burner_model_trainer.log     # Log file with detailed training/evaluation information
```

---

## ğŸ“¦ Installation

> **Python 3.8+ is required.**  
Install dependencies from the `requirements.txt` file:

```bash
pip install -r requirements.txt
```

**Required packages**:

- `pandas`
- `numpy`
- `joblib`
- `optuna`
- `mysql-connector-python`
- `scikit-learn`
- `xgboost`

---

## âš™ï¸ Configuration

Edit the database connection and training configuration in the `__main__` block:

```python
trainer = BurnerModelTrainer(
    host="your_mysql_host",
    user="your_username",
    password="your_password",
    database="your_database",
    table_name="your_table"
)
trainer.run()
```

---

## ğŸ’§ Main Functionalities

| Functionality            | Description                                                        |
|-------------------------|--------------------------------------------------------------------|
| **MySQL Integration**   | Connects and fetches data from a live SQL table                    |
| **Feature Engineering** | Generates domain-specific features like `FUEL_PER_PROD`            |
| **Outlier Filtering**   | Automatically removes extreme `BURNER_POWER` values               |
| **HPO with Optuna**     | Finds best model parameters using Bayesian optimization           |
| **Model Training**      | Fits an `XGBRegressor` to transformed targets                      |
| **Evaluation**          | Calculates metrics: MAE, RMSE, RÂ², MAPE, etc.                    |
| **Model Export**        | Saves the trained model and transformer as `.pkl`                 |
| **Metrics Logging**     | Saves results in a log file and a custom SQL table                |

---

## ğŸ“Š Sample Output Metrics

```
MAE:                12.8765
RMSE:               15.2893
RÂ² Score:           0.9142
MAPE:               4.57%
Explained Var.:     0.9151
Max Error:          33.41
Median Abs Error:   9.23
```

âœ… All logs are saved to `logs/burner_model_trainer.log`  
âœ… Metrics are also inserted into a MySQL table for future monitoring

---

## ğŸ§¦ Evaluation Metrics Explained

| Metric                | Description                                  |
|----------------------|----------------------------------------------|
| **MAE**              | Mean Absolute Error                          |
| **RMSE**             | Root Mean Squared Error                      |
| **RÂ² Score**         | Coefficient of Determination                 |
| **MAPE**             | Mean Absolute Percentage Error               |
| **Explained Var.**   | Proportion of variance explained by model   |
| **Max Error**        | Largest absolute difference                  |
| **Median AE**        | Median absolute error                        |

---

## ğŸ¤– Usage Example

```bash
# Run the training script
python burner_model_trainer.py
```

> Make sure your MySQL credentials and table names are correct before execution.

---

## ğŸ“ƒ License

This project is licensed under the **MIT License**.  
Feel free to use, modify, and distribute it for personal or commercial use.

ğŸ”— See the full [LICENSE](LICENSE) file.

---

## ğŸ¤ Contact

For questions, suggestions, or collaboration:

**Deuser Tech Group**  
ğŸ“§ Email: iafontal@deuser.es  
ğŸŒ Website: [Deuser](https://deuser.es/)

---

## âœ¨ Acknowledgements

- [Optuna](https://optuna.org/) â€“ For powerful hyperparameter optimization
- [XGBoost](https://xgboost.readthedocs.io/) â€“ High-performance machine learning library
- [Scikit-learn](https://scikit-learn.org/) â€“ Model evaluation tools

---

This contribution has received funding from the European Union's HORIZON-CL4-20-21-TWIN-TRANSITION-01 programme under grant agreement No 10.1058715 - [Self-X-AIPI project website](https://s-x-aipi-project.eu/)

<p align="center">
  <img src="https://github.com/user-attachments/assets/d7d86d47-edc0-468a-89da-84e13ad3ffea" width="200" alt="EU logo">
  &nbsp;&nbsp;
  <img src="https://github.com/user-attachments/assets/b8738b8e-c69f-43f7-a434-0a847ad429bc" width="220" alt="SX AIPI logo">
</p>

> Made with â¤ï¸ for industrial AI projects and continuous improvement.
